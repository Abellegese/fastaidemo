{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "from fastbook import *\n",
    "from fastai.vision.all import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>1) Vision Learner</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cut': -2,\n",
       " 'split': <function fastai.vision.learner._resnet_split(m)>,\n",
       " 'stats': ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_meta[resnet50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): AdaptiveConcatPool2d(\n",
       "    (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "    (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "  )\n",
       "  (1): fastai.layers.Flatten(full=False)\n",
       "  (2): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (3): Dropout(p=0.25, inplace=False)\n",
       "  (4): Linear(in_features=40, out_features=512, bias=False)\n",
       "  (5): ReLU(inplace=True)\n",
       "  (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): Dropout(p=0.5, inplace=False)\n",
       "  (8): Linear(in_features=512, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_head(20,2) #bn_final=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m path \u001b[39m=\u001b[39m untar_data(URLs\u001b[39m.\u001b[39;49mPETS)\n",
      "File \u001b[1;32mc:\\Users\\yak\\MiniConda3\\lib\\site-packages\\fastai\\data\\external.py:136\u001b[0m, in \u001b[0;36muntar_data\u001b[1;34m(url, archive, data, c_key, force_download, base)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[39m\"\u001b[39m\u001b[39mDownload `url` using `FastDownload.get`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    135\u001b[0m d \u001b[39m=\u001b[39m FastDownload(fastai_cfg(), module\u001b[39m=\u001b[39mfastai\u001b[39m.\u001b[39mdata, archive\u001b[39m=\u001b[39marchive, data\u001b[39m=\u001b[39mdata, base\u001b[39m=\u001b[39mbase)\n\u001b[1;32m--> 136\u001b[0m \u001b[39mreturn\u001b[39;00m d\u001b[39m.\u001b[39;49mget(url, force\u001b[39m=\u001b[39;49mforce_download, extract_key\u001b[39m=\u001b[39;49mc_key)\n",
      "File \u001b[1;32mc:\\Users\\yak\\MiniConda3\\lib\\site-packages\\fastdownload\\core.py:118\u001b[0m, in \u001b[0;36mFastDownload.get\u001b[1;34m(self, url, extract_key, force)\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[39mif\u001b[39;00m data\u001b[39m.\u001b[39mexists(): \u001b[39mreturn\u001b[39;00m data\n\u001b[0;32m    117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdownload(url, force\u001b[39m=\u001b[39mforce)\n\u001b[1;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract(url, extract_key\u001b[39m=\u001b[39;49mextract_key, force\u001b[39m=\u001b[39;49mforce)\n",
      "File \u001b[1;32mc:\\Users\\yak\\MiniConda3\\lib\\site-packages\\fastdownload\\core.py:110\u001b[0m, in \u001b[0;36mFastDownload.extract\u001b[1;34m(self, url, extract_key, force)\u001b[0m\n\u001b[0;32m    108\u001b[0m dest \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_path(extract_key)\n\u001b[0;32m    109\u001b[0m dest\u001b[39m.\u001b[39mmkdir(exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, parents\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 110\u001b[0m \u001b[39mreturn\u001b[39;00m untar_dir(arch, dest, rename\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, overwrite\u001b[39m=\u001b[39;49mforce)\n",
      "File \u001b[1;32mc:\\Users\\yak\\MiniConda3\\lib\\site-packages\\fastcore\\xtras.py:175\u001b[0m, in \u001b[0;36muntar_dir\u001b[1;34m(fname, dest, rename, overwrite)\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[39mif\u001b[39;00m overwrite: shutil\u001b[39m.\u001b[39mrmtree(dest) \u001b[39mif\u001b[39;00m dest\u001b[39m.\u001b[39mis_dir() \u001b[39melse\u001b[39;00m dest\u001b[39m.\u001b[39munlink()\n\u001b[0;32m    174\u001b[0m     \u001b[39melse\u001b[39;00m: \u001b[39mreturn\u001b[39;00m dest\n\u001b[1;32m--> 175\u001b[0m \u001b[39mif\u001b[39;00m rename: src \u001b[39m=\u001b[39m _unpack(fname, out)\n\u001b[0;32m    176\u001b[0m shutil\u001b[39m.\u001b[39mmove(\u001b[39mstr\u001b[39m(src), dest)\n\u001b[0;32m    177\u001b[0m \u001b[39mreturn\u001b[39;00m dest\n",
      "File \u001b[1;32mc:\\Users\\yak\\MiniConda3\\lib\\site-packages\\fastcore\\xtras.py:157\u001b[0m, in \u001b[0;36m_unpack\u001b[1;34m(fname, out)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_unpack\u001b[39m(fname, out):\n\u001b[0;32m    156\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mshutil\u001b[39;00m\n\u001b[1;32m--> 157\u001b[0m     shutil\u001b[39m.\u001b[39;49munpack_archive(\u001b[39mstr\u001b[39;49m(fname), \u001b[39mstr\u001b[39;49m(out))\n\u001b[0;32m    158\u001b[0m     ls \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mls()\n\u001b[0;32m    159\u001b[0m     \u001b[39mreturn\u001b[39;00m ls[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(ls) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\yak\\MiniConda3\\lib\\shutil.py:1269\u001b[0m, in \u001b[0;36munpack_archive\u001b[1;34m(filename, extract_dir, format)\u001b[0m\n\u001b[0;32m   1267\u001b[0m func \u001b[39m=\u001b[39m _UNPACK_FORMATS[\u001b[39mformat\u001b[39m][\u001b[39m1\u001b[39m]\n\u001b[0;32m   1268\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(_UNPACK_FORMATS[\u001b[39mformat\u001b[39m][\u001b[39m2\u001b[39m])\n\u001b[1;32m-> 1269\u001b[0m func(filename, extract_dir, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\yak\\MiniConda3\\lib\\shutil.py:1202\u001b[0m, in \u001b[0;36m_unpack_tarfile\u001b[1;34m(filename, extract_dir)\u001b[0m\n\u001b[0;32m   1199\u001b[0m     \u001b[39mraise\u001b[39;00m ReadError(\n\u001b[0;32m   1200\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is not a compressed or uncompressed tar file\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m filename)\n\u001b[0;32m   1201\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1202\u001b[0m     tarobj\u001b[39m.\u001b[39;49mextractall(extract_dir)\n\u001b[0;32m   1203\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1204\u001b[0m     tarobj\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\yak\\MiniConda3\\lib\\tarfile.py:2045\u001b[0m, in \u001b[0;36mTarFile.extractall\u001b[1;34m(self, path, members, numeric_owner)\u001b[0m\n\u001b[0;32m   2043\u001b[0m         tarinfo\u001b[39m.\u001b[39mmode \u001b[39m=\u001b[39m \u001b[39m0o700\u001b[39m\n\u001b[0;32m   2044\u001b[0m     \u001b[39m# Do not set_attrs directories, as we will do that further down\u001b[39;00m\n\u001b[1;32m-> 2045\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract(tarinfo, path, set_attrs\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m tarinfo\u001b[39m.\u001b[39;49misdir(),\n\u001b[0;32m   2046\u001b[0m                  numeric_owner\u001b[39m=\u001b[39;49mnumeric_owner)\n\u001b[0;32m   2048\u001b[0m \u001b[39m# Reverse sort directories.\u001b[39;00m\n\u001b[0;32m   2049\u001b[0m directories\u001b[39m.\u001b[39msort(key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m a: a\u001b[39m.\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\yak\\MiniConda3\\lib\\tarfile.py:2086\u001b[0m, in \u001b[0;36mTarFile.extract\u001b[1;34m(self, member, path, set_attrs, numeric_owner)\u001b[0m\n\u001b[0;32m   2083\u001b[0m     tarinfo\u001b[39m.\u001b[39m_link_target \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, tarinfo\u001b[39m.\u001b[39mlinkname)\n\u001b[0;32m   2085\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2086\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extract_member(tarinfo, os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(path, tarinfo\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m   2087\u001b[0m                          set_attrs\u001b[39m=\u001b[39;49mset_attrs,\n\u001b[0;32m   2088\u001b[0m                          numeric_owner\u001b[39m=\u001b[39;49mnumeric_owner)\n\u001b[0;32m   2089\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   2090\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merrorlevel \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\yak\\MiniConda3\\lib\\tarfile.py:2159\u001b[0m, in \u001b[0;36mTarFile._extract_member\u001b[1;34m(self, tarinfo, targetpath, set_attrs, numeric_owner)\u001b[0m\n\u001b[0;32m   2156\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dbg(\u001b[39m1\u001b[39m, tarinfo\u001b[39m.\u001b[39mname)\n\u001b[0;32m   2158\u001b[0m \u001b[39mif\u001b[39;00m tarinfo\u001b[39m.\u001b[39misreg():\n\u001b[1;32m-> 2159\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmakefile(tarinfo, targetpath)\n\u001b[0;32m   2160\u001b[0m \u001b[39melif\u001b[39;00m tarinfo\u001b[39m.\u001b[39misdir():\n\u001b[0;32m   2161\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmakedir(tarinfo, targetpath)\n",
      "File \u001b[1;32mc:\\Users\\yak\\MiniConda3\\lib\\tarfile.py:2208\u001b[0m, in \u001b[0;36mTarFile.makefile\u001b[1;34m(self, tarinfo, targetpath)\u001b[0m\n\u001b[0;32m   2206\u001b[0m     target\u001b[39m.\u001b[39mtruncate()\n\u001b[0;32m   2207\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2208\u001b[0m     copyfileobj(source, target, tarinfo\u001b[39m.\u001b[39;49msize, ReadError, bufsize)\n",
      "File \u001b[1;32mc:\\Users\\yak\\MiniConda3\\lib\\tarfile.py:253\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[1;34m(src, dst, length, exception, bufsize)\u001b[0m\n\u001b[0;32m    250\u001b[0m     dst\u001b[39m.\u001b[39mwrite(buf)\n\u001b[0;32m    252\u001b[0m \u001b[39mif\u001b[39;00m remainder \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 253\u001b[0m     buf \u001b[39m=\u001b[39m src\u001b[39m.\u001b[39;49mread(remainder)\n\u001b[0;32m    254\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(buf) \u001b[39m<\u001b[39m remainder:\n\u001b[0;32m    255\u001b[0m         \u001b[39mraise\u001b[39;00m exception(\u001b[39m\"\u001b[39m\u001b[39munexpected end of data\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\yak\\MiniConda3\\lib\\gzip.py:300\u001b[0m, in \u001b[0;36mGzipFile.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39merrno\u001b[39;00m\n\u001b[0;32m    299\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(errno\u001b[39m.\u001b[39mEBADF, \u001b[39m\"\u001b[39m\u001b[39mread() on write-only GzipFile object\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 300\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_buffer\u001b[39m.\u001b[39;49mread(size)\n",
      "File \u001b[1;32mc:\\Users\\yak\\MiniConda3\\lib\\_compression.py:68\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreadinto\u001b[39m(\u001b[39mself\u001b[39m, b):\n\u001b[0;32m     67\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mmemoryview\u001b[39m(b) \u001b[39mas\u001b[39;00m view, view\u001b[39m.\u001b[39mcast(\u001b[39m\"\u001b[39m\u001b[39mB\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m byte_view:\n\u001b[1;32m---> 68\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m(byte_view))\n\u001b[0;32m     69\u001b[0m         byte_view[:\u001b[39mlen\u001b[39m(data)] \u001b[39m=\u001b[39m data\n\u001b[0;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(data)\n",
      "File \u001b[1;32mc:\\Users\\yak\\MiniConda3\\lib\\gzip.py:493\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    490\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new_member \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \u001b[39m# Read a chunk of data from the file\u001b[39;00m\n\u001b[1;32m--> 493\u001b[0m buf \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mread(io\u001b[39m.\u001b[39;49mDEFAULT_BUFFER_SIZE)\n\u001b[0;32m    495\u001b[0m uncompress \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decompressor\u001b[39m.\u001b[39mdecompress(buf, size)\n\u001b[0;32m    496\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_decompressor\u001b[39m.\u001b[39munconsumed_tail \u001b[39m!=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\yak\\MiniConda3\\lib\\gzip.py:87\u001b[0m, in \u001b[0;36m_PaddedFile.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, size):\n\u001b[0;32m     86\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 87\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfile\u001b[39m.\u001b[39;49mread(size)\n\u001b[0;32m     88\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read \u001b[39m+\u001b[39m size \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_length:\n\u001b[0;32m     89\u001b[0m         read \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path = untar_data(URLs.PETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path.BASE_PATH = path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = get_image_files(path/'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseImage(fastuple):\n",
    "    def show(self, ctx=None, **kwargs):\n",
    "        img1,img2,same_breed = self\n",
    "        if not isinstance(img1, Tensor):\n",
    "            if img2.size != img1.size:\n",
    "                img2 = img2.resize(img.size)\n",
    "                img1t, img2t = tensor(img1), tensor(img2)\n",
    "                #we can use einops here\n",
    "                img1t,img2t = img1t.permute(2,0,1), img2t.permute(2,0,1)\n",
    "        else: img1t, img2t = img1, img2\n",
    "        line = img1t.new_zeros(img1t.shape[0], img1t.shape[1], 10)\n",
    "        return show_image(torch.cat([img1t,line, img2t], dim=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func(fname):\n",
    "    return re.match(r'^(.*)_\\d+.jpg$', fname.name).groups()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseTransform(Transform):\n",
    "    def __init__(self,files,label_func, splits):\n",
    "        self.labels = files.map(label_func).unique()\n",
    "        self.lbl2files = {l: L(f for f in files if label_func(f)==l) for l in self.labels}\n",
    "        self.label_func = label_func\n",
    "        self.valid = {f: self._draw(f) for f in files[splits[1]]}\n",
    "    def encodes(self, f):\n",
    "        f2,t = self.valid.get(f, self._draw(f))\n",
    "        img1, img2 = PILImage.create(f), PILImage.create(f2)\n",
    "        return SiameseImage(img1, img2, t)\n",
    "    def _draw(self, f):\n",
    "        same = random.random() < 0.5\n",
    "        cls = self.label_func(f)\n",
    "        if not same:\n",
    "            cls = random.choice(L(l for l in self.labels if l != cls))\n",
    "        return random.choice(self.lbl2files[cls]), same\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Data Splitting and Loading</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = RandomSplitter()(files)\n",
    "transformed = SiameseTransform(files, label_func, splits)\n",
    "tls = TfmdLists(files, transformed, splits=splits)\n",
    "dls = tls.dataloaders(after_item=[Resize(224), ToTensor],\n",
    "                      after_batch=[IntToFloatTensor, Normalize.from_stats(*imagenet_stats)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Custom Siamese Model Based on Pretrained</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseModel(Module):\n",
    "    def __init__(self, encoder, head):\n",
    "        self.encoder, self.head = encoder, head\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        ftrs = torch.cat([self.encoder(x1), self.encoder(x2)], dim=1)\n",
    "        return self.head(ftrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = create_body(resnet34, cut=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = create_head(512*2, 2, ps=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SiameseModel(encoder, head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(out, targ):\n",
    "    return nn.CrossEntropyLoss()(out, targ.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def siamese_splitter(model): return [params(model.encoder), params(model.head)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Constructing Learner</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = Learner(dls, model, loss_func=loss_func, splitter=siamese_splitter, metrics=accuracy)\n",
    "learner.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit_one_cycle(4, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Unfreezing and Fine-Tuning</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.unfreeze()\n",
    "learner.fit_one_cycle(4, slice(1e-6,1e-4)) #low lr for body and high lr for head"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
